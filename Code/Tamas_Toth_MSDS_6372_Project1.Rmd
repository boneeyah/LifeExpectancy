---
title: "MSDS_6372_Project1"
author: "Miguel Bonilla, Reuven Derner, Milan Patel, Tamas Toth"
date: '2022-05-27'
output:
  #html_document:
    #theme: cerulean
    #highlight: textmate
  github_document:
  toc: FALSE
  toc_depth: 3
  fig_width: 7
  fig_height: 5
  dev: "png"
  df_print: "default"
  includes: NULL
  md_extensions: NULL
  hard_line_breaks: TRUE
  pandoc_args: NULL
  html_preview: TRUE
  keep_html: TRUE
always_allow_html: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#### Loading the necessary R libraries for the analysis
```{r message = FALSE}
# Load the necessary libraries
library(knitr)
library(rmarkdown)
library(ggpubr)
library(dplyr)
library(tidyr)
library(plyr)
library(ggplot2)
library(tidyverse)
library(ggthemes)
library(e1071)
library(class)
library(caret)
library(stringr)
library(sjPlot)
library(data.table)
library(reshape2)
library(corrplot)
library(naivebayes)
library(car)
library(egg)
library(rworldmap)
library(Hmisc)
library(DataExplorer)
library(selectiveInference)
library(dlookr)
```
```{r message = FALSE}
# Turn off scientific notation
options(scipen = 100, digits = 4)
```
#### Read the data
```{r,fig.align='center',out.extra='angle=90', message = FALSE}
#Read the data
#setwd('/Users/ttoth76/Downloads/SMU/Semester_2/DS 6372 Applied Statistics_Inference & Modeling/FLS/Project1_Summer2022/GitContent/LifeExpectancy')
LifeExp = read.csv(file = 'Life_Expectancy_Data.csv',header = TRUE, sep = ",")
# take a sample of 15 from the dataframe
LifeExp_sample = sample_n(LifeExp, 5)
knitr::kable(LifeExp_sample, "html")
```

#### Address the missing values in each column (NA as well as empty strings).
```{r}
# Address the missing values in each column (NA as well as empty strings).
missing_df = as.data.frame(sapply(LifeExp, function(x) sum(is.na(x))))
colnames(missing_df) = c("variable missing")
knitr::kable(missing_df, "html")
empty_string_df = as.data.frame(sapply(LifeExp, function(x) sum(x == "")))
colnames(empty_string_df) = c("variable empty")
knitr::kable(empty_string_df, "html")
```

```{r}
#set random seed
set.seed(329)
```

```{r, warning=FALSE}
# Function to Identify different characteristics of the data frame 
# Getting a concise summary of the dataframe: str()
# Listing the column labels of the dataframe: colnames()
# Size of the dataset: dim()
# # Verify if there is any negative values in the dataset
dfinfo = function(df_name)
  {
  df_structure = str(df_name)
  df_colnames = colnames(df_name)
  df_dimensions = dim(df_name)
  df_neg = print(paste("Negative values in the Data Frame:", 
                       sapply(df_name, function(x) sum(x < 0))))
  outparam = list(df_structure, df_colnames, df_dimensions, df_neg)
  return (outparam)
}
```
```{r}
dfinfo(LifeExp)
```


#### Generate summary statistics
```{r}
# Generate summary statistics
summary(LifeExp)
```

### Observations:
* The dataset is comprised of 2938 observations and 22 variables
* There are numerical and categorical variables (Country and Status) in the dataset
* Column names have spaces and special characters that has been replaced by R with "."
* There are missing values or empty strings in the dataset
* No duplicated records
* 'Life.expectancy' is the dependent variable - There are 10 missing observations in the dependent variable
* We need to predict Salary however there is no salary variable in the dataset but MonthlyIncome variable seems to be sufficient for this purpose.


### Scatterplots
```{r Linear regression}
#####################################################################################
#                        Scatter plots for checking linearity                       #
#####################################################################################

################### Linear - Linear ###################
LifeExp$Status = as.factor(LifeExp$Status)
#num_cols = LifeExp %>% select(where(is.numeric)) %>% colnames()
#MLR_num_LE = LifeExp[, num_cols]
pairs(Life.expectancy~Year+Adult.Mortality+infant.deaths+Alcohol, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Linear Scatter Plot")
pairs(Life.expectancy~log(percentage.expenditure)+Hepatitis.B+Measles+BMI, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Linear Scatter Plot")
pairs(Life.expectancy~under.five.deaths+Polio+Total.expenditure+Diphtheria, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Linear Scatter Plot")
pairs(Life.expectancy~HIV.AIDS+GDP+Population+thinness..1.19.years, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Linear Scatter Plot")
pairs(Life.expectancy~thinness.5.9.years+Income.composition.of.resources+Schooling, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Linear Scatter Plot")


################### Linear - Log transformation ###################
LifeExp$Status = as.factor(LifeExp$Status)
#num_cols = LifeExp %>% select(where(is.numeric)) %>% colnames()
#MLR_num_LE = LifeExp[, num_cols]
pairs(Life.expectancy~Year+Adult.Mortality+infant.deaths+Alcohol, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Log Scatter Plot")
pairs(Life.expectancy~log(percentage.expenditure)+Hepatitis.B+Measles+BMI, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Log Scatter Plot")
pairs(Life.expectancy~under.five.deaths+Polio+Total.expenditure+Diphtheria, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Log Scatter Plot")
pairs(Life.expectancy~log(HIV.AIDS)+log(GDP)+Population+thinness..1.19.years, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Log Scatter Plot")
pairs(Life.expectancy~thinness.5.9.years+Income.composition.of.resources+Schooling, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Linear-Log Scatter Plot")

################### Log - Log transformation ###################
LifeExp$Status = as.factor(LifeExp$Status)
#num_cols = LifeExp %>% select(where(is.numeric)) %>% colnames()
#MLR_num_LE = LifeExp[, num_cols]
pairs(log(Life.expectancy)~Year+Adult.Mortality+infant.deaths+Alcohol, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Log-Log Scatter Plot")
pairs(log(Life.expectancy)~log(percentage.expenditure)+Hepatitis.B+Measles+BMI, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Log-Log Scatter Plot")
pairs(log(Life.expectancy)~under.five.deaths+Polio+Total.expenditure+Diphtheria, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Log-Log Scatter Plot")
pairs(log(Life.expectancy)~log(HIV.AIDS)+log(GDP)+Population+thinness..1.19.years, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Log-Log Scatter Plot")
pairs(log(Life.expectancy)~thinness.5.9.years+Income.composition.of.resources+Schooling, data=LifeExp, col=ifelse(LifeExp$Status=="Developed", "green", "red"), main = "Log-Log Scatter Plot")
```

### Observations
We can observe linear relationship between Life Expectancy and the following variables

* Income composition of resources
* Schooling
* Log(HIV.AIDS)
* Log(GDP)
* Log(percentage.expenditure)
* BMI
* Year
* Adult.Mortality

#adding region column to do regional imputation
```{r adding region column}
###rename ivory coast and remove parenthesis from country names
LifeExp$Country <- replace(LifeExp$Country,LifeExp$Country == "CÃ´te d'Ivoire","Ivory Coast")
LifeExp$Country <-  str_replace(LifeExp$Country,"\\(.*\\)","")
LifeExp$Country <- trimws(LifeExp$Country,"right")

### add region using rworldmap package
regions <- rworldmap::countryRegions
regions <- regions[,c(2,6)]
colnames(regions) <- c("Country","Region")
regions$Country <- replace(regions$Country, regions$Country == "The Bahamas", "Bahamas")
regions$Country <- replace(regions$Country, regions$Country == "Brunei", "Brunei Darussalam")
regions$Country <- replace(regions$Country, regions$Country == "Cape Verde", "Cabo Verde")
regions$Country <- replace(regions$Country, regions$Country == "Republic of the Congo", "Congo")
regions$Country <- replace(regions$Country, regions$Country == "Czech Republic", "Czechia")
regions$Country <- replace(regions$Country, regions$Country == "North Korea", "Democratic People's Republic of Korea")
regions$Country <- replace(regions$Country, regions$Country == "Guinea Bissau", "Guinea-Bissau")
regions$Country <- replace(regions$Country, regions$Country == "Laos","Lao People's Democratic Republic")
regions$Country <- replace(regions$Country, regions$Country == "Federated States of Micronesia", "Micronesia")
regions$Country <- replace(regions$Country, regions$Country == "South Korea", "Republic of Korea")
regions$Country <- replace(regions$Country, regions$Country == "Moldova", "Republic of Moldova")
regions$Country <- replace(regions$Country, regions$Country == "Russia", "Russian Federation")
regions$Country <- replace(regions$Country, regions$Country == "Republic of Serbia", "Serbia")
regions$Country <- replace(regions$Country, regions$Country == "Syria", "Syrian Arab Republic")
regions$Country <- replace(regions$Country, regions$Country == "Macedonia", "The former Yugoslav republic of Macedonia")
regions$Country <- replace(regions$Country, regions$Country == "East Timor", "Timor-Leste")
regions$Country <- replace(regions$Country, regions$Country == "United Kingdom", "United Kingdom of Great Britain and Northern Ireland")
regions$Country <- replace(regions$Country, regions$Country == "Vietnam", "Viet Nam")

LifeExp <-  join(LifeExp,regions,by = "Country", type = 'left')
LifeExp$Country <- replace(LifeExp$Country, LifeExp$Country == "Micronesia", "Micronesia (Federated States of)")
LifeExp$Region <- as.factor(LifeExp$Region)
```


## Fixing the missing values by replacing with median
```{r median imputation}
# Drop missing values from the dependent variable
LifeExp = LifeExp[!(is.na(LifeExp$Life.expectancy)),]

na_list = colnames(LifeExp)[apply(LifeExp, 2, anyNA)]
# LifeExp_db = apply(LifeExp[,colnames(LifeExp) %in% na_list],2,median,na.rm =  TRUE)
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Alcohol = replace(Alcohol,is.na(Alcohol), median(Alcohol, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Hepatitis.B = replace(Hepatitis.B,is.na(Hepatitis.B), median(Hepatitis.B, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(BMI = replace(BMI,is.na(BMI), median(BMI, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Polio = replace(Polio,is.na(Polio), median(Polio, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Total.expenditure = replace(Total.expenditure,is.na(Total.expenditure), median(Total.expenditure, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Diphtheria = replace(Diphtheria,is.na(Diphtheria), median(Diphtheria, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(GDP = replace(GDP,is.na(GDP), median(GDP, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Population = replace(Population,is.na(Population), median(Population, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(thinness..1.19.years = replace(thinness..1.19.years,is.na(thinness..1.19.years), median(thinness..1.19.years, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(thinness.5.9.years = replace(thinness.5.9.years,is.na(thinness.5.9.years), median(thinness.5.9.years, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Income.composition.of.resources = replace(Income.composition.of.resources,is.na(Income.composition.of.resources), median(Income.composition.of.resources, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Country) %>% dplyr::mutate(Schooling = replace(Schooling,is.na(Schooling), median(Schooling, na.rm = TRUE)))

#repeat grouping by Region for countries which have only NAs
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Alcohol = replace(Alcohol,is.na(Alcohol), median(Alcohol, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Hepatitis.B = replace(Hepatitis.B,is.na(Hepatitis.B), median(Hepatitis.B, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(BMI = replace(BMI,is.na(BMI), median(BMI, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Polio = replace(Polio,is.na(Polio), median(Polio, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Total.expenditure = replace(Total.expenditure,is.na(Total.expenditure), median(Total.expenditure, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Diphtheria = replace(Diphtheria,is.na(Diphtheria), median(Diphtheria, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(GDP = replace(GDP,is.na(GDP), median(GDP, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Population = replace(Population,is.na(Population), median(Population, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(thinness..1.19.years = replace(thinness..1.19.years,is.na(thinness..1.19.years), median(thinness..1.19.years, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(thinness.5.9.years = replace(thinness.5.9.years,is.na(thinness.5.9.years), median(thinness.5.9.years, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Income.composition.of.resources = replace(Income.composition.of.resources,is.na(Income.composition.of.resources), median(Income.composition.of.resources, na.rm = TRUE)))
LifeExp = LifeExp %>% group_by(Region) %>% dplyr::mutate(Schooling = replace(Schooling,is.na(Schooling), median(Schooling, na.rm = TRUE)))
# convert the tibble to data frame
LifeExp = as.data.frame(LifeExp)

#impute USA values
#USA GDP
US_GDP <- read.csv('API_NY.GDP.PCAP.CD_DS2_en_csv_v2_4150786.csv',header = FALSE)
colnames(US_GDP) <- US_GDP[3,]
US_GDP <- rename(US_GDP,c("Country Name"="Country"))
US_GDP <- US_GDP[US_GDP$Country == "United States",c(1,45:60)]
US_GDP <- US_GDP %>% pivot_longer(!Country,names_to = "Year",values_to = "GDP2")
US_GDP$Country <- replace(US_GDP$Country, US_GDP$Country == "United States", "United States of America")
US_GDP$Year <- as.integer(US_GDP$Year)

LifeExp <- left_join(LifeExp,US_GDP, by=c("Country","Year"))
LifeExp <- LifeExp %>% dplyr::mutate(GDP = ifelse(LifeExp$Country == "United States of America", LifeExp$GDP2, LifeExp$GDP))

#US Schooling
US_Scho <- read.csv("Expected years of schooling (years).csv",skip = 6,header = FALSE)
colnames(US_Scho) <- US_Scho[1,]
US_Scho$Country <- trimws(US_Scho$Country, which = "both")
US_Scho <- US_Scho[US_Scho$Country == "United States", colSums(is.na(US_Scho)) !=nrow(US_Scho)]
US_Scho <- US_Scho[,c(2,13:28)]
US_Scho <- US_Scho %>% pivot_longer(!Country,names_to = "Year",values_to = "Schooling2")
US_Scho$Year <- as.integer(US_Scho$Year)
US_Scho$Schooling2 <- as.numeric(US_Scho$Schooling2)
US_Scho$Country <- replace(US_Scho$Country, US_Scho$Country == "United States", "United States of America")


LifeExp <- left_join(LifeExp,US_Scho,by=c("Country","Year"))
LifeExp <- LifeExp %>% dplyr::mutate(Schooling =ifelse(LifeExp$Country == "United States of America",LifeExp$Schooling2,LifeExp$Schooling))

#US income composition
US_Inc <- read.csv('Income index.csv',skip = 5, header = FALSE)
colnames(US_Inc) <- US_Inc[1,]
US_Inc$Country <- trimws(US_Inc$Country,which = "both")
US_Inc <- US_Inc[US_Inc$Country == "United States",colSums(is.na(US_Inc)) !=nrow(US_Inc)]
US_Inc <- US_Inc[,c(2,13:28)]
US_Inc <- US_Inc %>%  pivot_longer(!Country,names_to = "Year", values_to = "comp2")
US_Inc$Year <- as.integer(US_Inc$Year)
US_Inc$comp2 <- as.numeric(US_Inc$comp2)
US_Inc$Country <- replace(US_Inc$Country,US_Inc$Country == "United States", "United States of America")

LifeExp <- left_join(LifeExp,US_Inc,by=c("Country","Year"))
LifeExp <- LifeExp %>% dplyr::mutate("Income.composition.of.resources" = ifelse(LifeExp$Country == "United States of America", LifeExp$comp2,LifeExp$Income.composition.of.resources))

#Add population from external source
#data from UN in thousands 
pop_all <- read.csv('WPP2019_TotalPopulationBySex.csv')
pop_all <- pop_all %>% dplyr::select(Country = Location, Year = Time, Population2 = PopTotal) %>% mutate(Population2 = Population2*1000) %>% filter(Year %in% c(2000:2015))

#clean country names to match before merge
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "Bolivia (Plurinational State of)", "Bolivia")
pop_all$Country <- replace(pop_all$Country,pop_all$Country == "CÃ´te d'Ivoire", "Ivory Coast")
pop_all$Country <- replace(pop_all$Country,pop_all$Country == "Dem. People's Republic of Korea","Democratic People's Republic of Korea")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "Iran (Islamic Republic of)", "Iran")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "Micronesia (Fed. States of)", "Micronesia (Federated States of)")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "Eswatini", "Swaziland")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "North Macedonia", "The former Yugoslav republic of Macedonia")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "United Kingdom", "United Kingdom of Great Britain and Northern Ireland")
pop_all$Country <- replace(pop_all$Country, pop_all$Country == "Venezuela (Bolivarian Republic of)", "Venezuela")
LifeExp<- left_join(LifeExp,pop_all,by=c("Country","Year")) %>% mutate(Population = Population2)

#replace adult.mortality since there are clear mistakes with the data that could
#not be resolved with transformation of the variable
adlt_mort <- read.csv('Adult_mort.csv',header = TRUE)
adlt_mort <- adlt_mort %>% dplyr::select("Country" = Location,"Year" = Period,"Adult.Mort2" = Value)
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "CÃ´te dâIvoire","Ivory Coast")
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "Bolivia (Plurinational State of)","Bolivia")
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "Venezuela (Bolivarian Republic of)","Venezuela")
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "Iran (Islamic Republic of)", "Iran")
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "Eswatini", "Swaziland")
adlt_mort$Country <- replace(adlt_mort$Country,adlt_mort$Country == "The former Yugoslav Republic of Macedonia", "The former Yugoslav republic of Macedonia")

LifeExp <- left_join(LifeExp,adlt_mort, by=c("Country","Year"))
LifeExp <- LifeExp %>% 
  dplyr::mutate("Adult.Mortality" = Adult.Mort2)
#drop new variables
drop = c("GDP2","Schooling2","comp2", "Population2","Adult.Mort2")
LifeExp <- LifeExp[,!colnames(LifeExp) %in% drop]

### Transform countries to continents
library(countrycode)
LifeExp$Continent = countrycode(sourcevar = LifeExp[, "Country"], origin = "country.name", destination = "continent")
LifeExp$Continent = as.factor(LifeExp$Continent)

#LifeExpKNN = LifeExp


```

### Full Correlation Matrix for Linear Regression (Life.expectancy)
```{r fig.dim = c(14, 12), fig.align='center',out.extra='angle=90'}
#####################################################################################
#      Full Correlation Matrix for Linear Regression (Life.expectancy)              #
#####################################################################################
# Filter for data to be included
#num_cols = LifeExp %>% dplyr::select(where(is.numeric)) %>% colnames()
#LifeExpcorr = LifeExp[,num_cols]
#corrplot(cor(LifeExpcorr), method = 'square', order = 'AOE', addCoef.col = 'black', 
#         cl.pos = 'n', col = COL2('BrBG'))

plot_correlate(LifeExp)

```

### Observations
* Under five death and infant death are perfectly correlated. They are describing the same thing. One of the variable is redundant.
* GDP and percentage expenditure are perfectly correlated. They are describing the same thing. One of the variable is redundant.
* Schooling and Income Composition of Resources have a strong positive correlation
* Life Expectancy and Adult Mortality are highly negatively correlated
* Life Expectancy and HIV.AIDS are moderately correlated
* Life Expectancy and BMI are moderately correlated
* Life Expectancy and Schooling are highly correlated
* Life Expectancy and Income Composition of Resources are highly correlated

## Uni-variate analysis
```{r,fig.align='center',out.extra='angle=90'}
#####################################################################################
#                               Uni-variate analysis                                #
#####################################################################################
# Let's plot the summary statistics
# Univariate analysis
num_cols = LifeExp %>% dplyr::select(where(is.numeric)) %>% colnames()
num_cols_exclude = c('Year')
num_cols_plots = noquote(unlist(num_cols[!( num_cols %in% num_cols_exclude)]))
nrows = length(num_cols_plots)
for (i in num_cols_plots)
{
box_p = LifeExp %>%
  ggplot(aes(x="", y = .data[[i]])) +
  geom_boxplot(fill = "sandybrown", color = "black") + 
  coord_flip() + theme_classic() + xlab("") +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  ylab(i)
hist_p = LifeExp %>%
  ggplot() +
  geom_histogram(aes(x = .data[[i]], y = (..count..)/sum(..count..)),
                 position = "identity", bins = 30, 
                 fill = "sandybrown", color = "black") +
  ylab("Relative Frequency") +
  theme_classic() + xlab(i) + ggtitle(paste(i, "- Univariate Analysis")) + 
  theme(plot.title = element_text(hjust = 0.5))
egg::ggarrange(hist_p, box_p, heights = 2:1) 
}

```

### Categorical data plots
```{r,fig.align='center',out.extra='angle=90', fig.dim = c(8, 6)}
#####################################################################################
#                               Categorical data plots                              #
#####################################################################################
num_var = LifeExp %>% dplyr::select(where(is.numeric)) %>% colnames()
cat_cols = LifeExp %>% dplyr::select(where(is.factor)) %>% colnames()
num_ex = c('Year')
num_var_plots = noquote(unlist(num_var[!( num_var %in% num_ex)]))
# Plot all categorical variables
for (c in cat_cols)
{
  cat_plot = LifeExp %>% ggplot(aes(x= .data[[c]], group = 1)) + 
    geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat="count") +
    geom_text(aes( label = scales::percent(..prop..),
                   y= ..prop.. ), stat= "count", vjust = -.5) +
    labs(y = "Percent") +
    scale_y_continuous(labels = scales::percent) + theme(legend.position = "none") +
    ggtitle(paste(c, "Categorical Analysis")) + 
    theme(plot.title = element_text(hjust = 0.5)) + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) # +
    #scale_fill_brewer(palette="Oranges")
    egg::ggarrange(cat_plot, ncol=2) 
}
```

## Bi-variate analysis with Status variable
```{r,fig.align='center',out.extra='angle=90'}
#####################################################################################
#                     Bi-variate analysis with Status variable                      #
#####################################################################################
for (i in num_var_plots)
{
multibox = LifeExp %>%
  ggplot(aes(x=Status, y = .data[[i]])) +
  geom_boxplot(fill = "sandybrown", color = "black") + 
  xlab("Status") +
  ylab(i) + stat_summary(fun=mean, geom="point", shape=20, size=7, color="red", fill="red") +
  ggtitle(paste(i, "vs Status bi-variate analysis")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_brewer(palette = "Oranges")  
egg::ggarrange(multibox, ncol=2)
}
```

## Bi-variate analysis with Region variable
```{r,fig.align='center',out.extra='angle=90'}
#####################################################################################
#                     Bi-variate analysis with Region variable                   #
#####################################################################################
for (i in num_var_plots)
{
multibox = LifeExp %>%
  ggplot(aes(x=Region, y = .data[[i]])) +
  geom_boxplot(fill = "sandybrown", color = "black") + 
  xlab("Region") +
  ylab(i) + stat_summary(fun=mean, geom="point", shape=20, size=7, color="red", fill="red") +
  ggtitle(paste(i, "vs Region bi-variate analysis")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
    scale_fill_brewer(palette = "Oranges")  
egg::ggarrange(multibox, ncol=2)
}
```
## Overall life expectancy over time
```{r,fig.align='center',out.extra='angle=90'}
#####################################################################################
#                          Overall life expectancy over time                        #
#####################################################################################

mean_LifeExp = LifeExp %>% group_by(Year) %>% summarise_at(vars(Life.expectancy), list(meanle = mean))
mean_LifeExp_reg = LifeExp %>% group_by(Year, Region) %>% summarise_at(vars(Life.expectancy), list(meanle = mean))
mean_LifeExp_cont = LifeExp %>% group_by(Year, Continent) %>% summarise_at(vars(Life.expectancy), list(meanle = mean))

#Overall life expectancy
ggplot(data=mean_LifeExp, aes(x=Year, y=meanle)) +
  geom_line()+
  geom_point() +
   ggtitle("Mean life expactancy by year") +
  theme(plot.title = element_text(hjust = 0.5))+
   xlab("Year") + ylab("Average Life Expectancy")
  

#Overall life expectancy by Region
ggplot(data=mean_LifeExp_reg, aes(x=Year, y=meanle, group = Region)) +
  geom_line(aes(color=Region))+
  geom_point(aes(color=Region)) +
  ggtitle("Mean life expactancy by year by region") +
theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Year") + ylab("Average Life Expectancy")

#Overall life expectancy by Continent
ggplot(data=mean_LifeExp_cont, aes(x=Year, y=meanle, group = Continent)) +
  geom_line(aes(color=Continent))+
  geom_point(aes(color=Continent)) +
  ggtitle("Mean life expactancy by year by continent") +
theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Year") + ylab("Average Life Expectancy")

```


```{r transform variables in the dataframe}
#####################################################################################
#                                     Data Preparation                              #
#####################################################################################

### Log Transform variables
LifeExp = mutate(LifeExp, log.HIV.AIDS = ifelse(HIV.AIDS==0, log(HIV.AIDS+1), log(HIV.AIDS)))
LifeExp = mutate(LifeExp, log.GDP = ifelse(GDP==0, log(GDP+1), log(GDP)))
LifeExp = mutate(LifeExp, log.percentage.expenditure = ifelse(percentage.expenditure==0, log(percentage.expenditure+1), log(percentage.expenditure)))



### Make country as factor
LifeExp$Country = as.factor(LifeExp$Country)

#drop = c('HIV.AIDS', 'percentage.expenditure', 'GDP')#keeping country in
#LifeExp = LifeExp[, !(colnames(LifeExp) %in% drop)]

```

```{r train test set}
#####################################################################################
#                    Split the Data to Train and Test sets (85%-15%)               #
#####################################################################################
index<-sample(1:dim(LifeExp)[1],round(dim(LifeExp)[1]*0.85),replace=F)
train = LifeExp[index,]
test = LifeExp[-index,]

# Create training and test set for regression models
# Droping the variables which were log transformed, as well as country and region or countinent
#drop_for_reg = c(-1, -8, -16, -17, -27)
drop_for_reg = c("Country", "HIV.AIDS", "GDP", "percentage.expenditure", "Region")
rtrain = train[,!colnames(train) %in% drop_for_reg]
rtest = test[,!colnames(train) %in% drop_for_reg]
x=model.matrix(Life.expectancy~.,rtrain)[,-1]
y=rtrain$Life.expectancy
xtest = model.matrix(Life.expectancy~.,rtest)[,-1]
ytest = rtest$Life.expectancy

# Create training and test set for KNN model

incl_for_knn = c("Country", "Life.expectancy", "Adult.Mortality" , "Alcohol", "HIV.AIDS", "thinness.5.9.years" , "Status", "Income.composition.of.resources", "percentage.expenditure", "infant.deaths", "GDP")
ktrain = train[,incl_for_knn]
ktest = test[,incl_for_knn]
```



```{r EDA on Training Data}
#####################################################################################
#                             EDA on Train sets                                    #
#####################################################################################

describe(train)
```

## Observations

** A High degree of skewness can be identified in Infant Deaths
** A High degree of skewness can be identified in Measles
** A High degree of skewness can be identified in under.five.deaths	
** A High degree of skewness can be identified in Population


```{r normality}
normality(train) 
#Runs a Shapario-Wilk Tests, if the p-value is >= .05 then the data is normally distrusted, if <0.05 the data is not normally distrusted.

#Find Features that are not normally distributed 

train %>%
  normality() %>%
  filter(p_value < 0.05) %>%
  arrange(abs(p_value))

# Verify non normality and transformation options of the variability 
plot_normality(train)

```

## Observations

** The p-value of the Population is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.	
** The p-value of the Measles is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the infant.deaths is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the under.five.deaths is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the Hepatitis.B is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the Diphtheria is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the Polio is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the log.HIV.AIDS is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the thinness.5.9.years is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.
** The p-value of the thinness..1.19.years is less than 0.0001 signifying it is non normally and should be transformed if utilized in the following models.



#####################################################################################
#                                        Modeling                                   #
#####################################################################################

```{r Model building}
#Prediction function
predict.regsubsets =function (object , newdata ,id ,...){
  form=as.formula (object$call [[2]])
  mat=model.matrix(form ,newdata )
  coefi=coef(object ,id=id)
  xvars=names(coefi)
  mat[,xvars]%*%coefi
}

### Evaluation Data Frame
### test_ASE, R-squared/Adjusted R-squared
eval_train_df = data.frame()
eval_train_df = eval_train_df %>% dplyr::mutate(ID = row_number())

eval_test_df = data.frame()
eval_test_df = eval_test_df %>% dplyr::mutate(ID = row_number())

#####################################################################################
#                                       Lasso                                       #
#####################################################################################
library(glmnet)

grid=10^seq(10,-2, length =100)
lasso.mod=glmnet(x,y,alpha=1, lambda =grid)
cv.out=cv.glmnet(x,y,alpha=1)
plot(cv.out)

bestlambda = cv.out$lambda.min  #Optimal penalty parameter.  You can make this call visually.
lasso.pred=predict(lasso.mod ,s=bestlambda ,newx=xtest)

testMSE_LASSO<-mean((ytest-lasso.pred)^2)
testMSE_LASSO
coef(lasso.mod,s=bestlambda)

lasso_residuals = (ytest - lasso.pred)
hist(lasso_residuals, main = "Histogram of Residuals (LASSO)")
plot(lasso_residuals, main = "Residuals plot (LASSO)") 
abline(h=0, col="blue")

# Metrics RMSE; R-squared; MAE
postResample(pred = lasso.pred, obs = ytest)

##### Fit Linear Model based on LASSO regularization without factors to measure VIF####
#fit.lasso.lm = lm(Life.expectancy ~ Year + Adult.Mortality + Alcohol + Hepatitis.B + Measles + BMI + under.five.deaths + Polio + #Diphtheria + Population + thinness.5.9.years + Income.composition.of.resources + Schooling + log.GDP + #log.percentage.expenditure, data = train_lasso)

### Continent included
fit.lasso.lm = lm(Life.expectancy ~ Year + Adult.Mortality + Alcohol + Hepatitis.B + Measles + BMI + under.five.deaths + Polio + Diphtheria + Population + thinness..1.19.years + thinness.5.9.years + Income.composition.of.resources + Schooling + log.GDP + log.percentage.expenditure, data = rtrain)
summary(fit.lasso.lm)

### Visualize VIF
fit.lasso.lm_VIF = vif(fit.lasso.lm)
barplot(fit.lasso.lm_VIF, main = 'VIF Values (LASSO)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")


### Fit linear model with factors
#fit.lasso.lm3 = lm(Life.expectancy ~ Status + Region + Year + Adult.Mortality + Alcohol + Hepatitis.B + Measles + BMI + under.five.deaths + Polio + Diphtheria + Population + thinness.5.9.years + Income.composition.of.resources + Schooling + log.GDP + log.percentage.expenditure, data = train_lasso)

### Continent included
fit.lasso.lm3 = lm(Life.expectancy ~ Status + Continent + Year + Adult.Mortality + Alcohol + Hepatitis.B + Measles + BMI + under.five.deaths + Polio + Diphtheria + Population + thinness..1.19.years + thinness.5.9.years + Income.composition.of.resources + Schooling + log.GDP + log.percentage.expenditure, data = rtrain)

#### Hypothesis testing ####
summary(fit.lasso.lm3)
# At alpha = 0.05 the following variables are not significant therefore don't contribute to the model performance:
# Hepatitis.B, thinness.5.9.years, log.GDP, log.percentage.expenditure

# Predicting
train_pred = predict(fit.lasso.lm3, rtrain)
test_pred = predict(fit.lasso.lm3, rtest)

# Scoring the final model on Training and Test set
residuals = resid(fit.lasso.lm3)
train_score = postResample(pred = train_pred, obs = rtrain$Life.expectancy)
test_score = postResample(pred = test_pred, obs = rtest$Life.expectancy)
sm = summary(fit.lasso.lm3)
mse_trn = mean(sm$residuals^2)

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared


## Test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit.lasso.lm3$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

### Checking Multiple Liner Regression model assumptions
confint(fit.lasso.lm3)
hist(residuals, main = "Histogram of Residuals (Lasso MLR fit)")
plot(residuals, main = "Residuals plot (Lasso MLR fit)") 
abline(h=0, col="blue")
plot(fit.lasso.lm3, which = 2)
plot(fit.lasso.lm3, which = 4)

##### Visualize prediction vs actual
x_lasso = 1:dim(xtest)[1]
plot(x_lasso, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (LASSO)", ylab="Life expectancy")
lines(x_lasso, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("Original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (LASSO MLR fit)", xlab = 'Original observations', ylab='Predicted values')

### Evaluation Data Frame
### test_ASE, R-squared/Adjusted R-squared, RMSE
eval_test_df = data.frame(model_name = 'LASSO', MSE=format(round(mse,4),nsmall=4), R_Squared=format(round(rsqd,4),nsmall=4), AdjR_Squared=format(round(adjrsqd,4),nsmall=4), RMSE = format(round(rmse,4),nsmall=4))

### train_ASE, R-squared/Adjusted R-squared, RMSE
eval_train_df = data.frame(model_name = 'LASSO', MSE=format(round(mse_trndf,4),nsmall=4), R_Squared=format(round(rsqd_trn,4),nsmall=4), AdjR_Squared=format(round(adjrsqd_trn,4),nsmall=4), RMSE = format(round(rmse_trn,4),nsmall=4))


#####################################################################################
#                                  Forward Selection                                #
#####################################################################################
library(leaps)

mlr.fwd=regsubsets(Life.expectancy~.,data=rtrain,method="forward",nvmax=24)
testASE<-c()
for (i in 1:24){
  predictions = predict.regsubsets(object=mlr.fwd,newdata=rtest,id=i) 
  testASE[i] = mean((rtest$Life.expectancy-predictions)^2)
}
par(mfrow=c(1,1))
plot(1:24,testASE,type="l",xlab="# of predictors",ylab="test vs train ASE", main='Forward Selection plot')
index<-which(testASE==min(testASE))
points(index,testASE[index],col="red",pch=10)
rss<-summary(mlr.fwd)$rss
lines(1:24,rss/dim(rtrain)[1],lty=3,col="blue")  

mlr.fwd.final=regsubsets(Life.expectancy~.,data=LifeExp[,!colnames(train) %in% drop_for_reg],method="forward",nvmax=24)
coef(mlr.fwd.final,14)
summary(mlr.fwd.final)


# Metrics RMSE; R-squared; MAE
postResample(pred = predictions, obs = ytest)

##### Fit Linear Model based on Forward Selection without factors to measure VIF####
fit.fwd.lm = lm(Life.expectancy ~ Adult.Mortality+infant.deaths+Alcohol+under.five.deaths+Polio+
                                  Diphtheria + Income.composition.of.resources +
                                  Schooling + log.GDP, data = rtrain)
summary(fit.fwd.lm)


### Visualize VIF
fit.fwd.lm_VIF = vif(fit.fwd.lm)
barplot(fit.fwd.lm_VIF, main = 'VIF Values (FWD selection)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")


# We can see that Forward Selection did not remove infant.deaths or under.five.deaths as those are perfectly correlated. Let's remove the one with the smallest coefficient (infant.deaths).

##### Fit Linear Model based on FWD selection without factors to measure VIF####
fit.fwd.lm2 = lm(Life.expectancy ~ Adult.Mortality+Alcohol+under.five.deaths+Polio+
                                  Diphtheria + Income.composition.of.resources +
                                  Schooling + log.GDP, data = rtrain)
summary(fit.fwd.lm2)

### re-run Visualize VIF
fit.fwd.lm2_VIF = vif(fit.fwd.lm2)
barplot(fit.fwd.lm2_VIF, main = 'Re-test of VIF Values (FWD selection)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

##### Fit Linear Model based on Forward Selection regularization and removed multicollinearity and categorical variables####
fit.fwd.lm3 = lm(Life.expectancy ~ Status+Continent+Adult.Mortality+Alcohol+under.five.deaths+Polio+
                                  Diphtheria + Income.composition.of.resources +
                                  Schooling + log.GDP, data = rtrain)

#### Hypothesis testing ####
summary(fit.fwd.lm3)
# At alpha = 0.05 the following variables are not significant therefore don't contribute to the model performance:
# thinness.5.9.years, Measles, BMI, Total.expenditure.

# Predicting
train_pred = predict(fit.fwd.lm3, rtrain)
test_pred = predict(fit.fwd.lm3, rtest)

# Scoring the final model on Training and Test set
residuals = resid(fit.fwd.lm3)
train_score = postResample(pred = train_pred, obs = rtrain$Life.expectancy)
test_score = postResample(pred = test_pred, obs = rtest$Life.expectancy)
sm = summary(fit.fwd.lm3)
mse_trn = mean(sm$residuals^2)

### Checking Multiple Liner Regression model assumptions
confint(fit.fwd.lm3)
hist(residuals, main = "Histogram of Residuals")
plot(residuals, main = "Residuals plot") 
abline(h=0, col="blue")
plot(fit.fwd.lm3, which = 2)
plot(fit.fwd.lm3, which = 4)

##### Visualize prediction vs actual
x_fwd = 1:dim(xtest)[1]
plot(x_fwd, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (FWD selection)", ylab="Life expectancy")
lines(x_fwd, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (FWD Selection fit)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit.lasso.lm3$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared

eval_test_df = rbind(eval_test_df, c('FWD Selection', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('FWD Selection', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse_trn,4),nsmall=4)))
#####################################################################################
#                               Backward Elimination                                #
#####################################################################################

mlr.bck=regsubsets(Life.expectancy~.,data=rtrain,method="backward",nvmax=24)
testASE<-c()
for (i in 1:24){

  predictions = predict.regsubsets(object=mlr.bck,newdata=test,id=i) 
  testASE[i] = mean((test$Life.expectancy-predictions)^2)
}

par(mfrow=c(1,1))
plot(1:24,testASE,type="l",xlab="# of predictors",ylab="test vs train ASE")
index<-which(testASE==min(testASE))
points(index,testASE[index],col="red",pch=10)
rss<-summary(mlr.bck)$rss
lines(1:24,rss/dim(rtrain)[1],lty=3,col="blue")  

mlr.bck.final=regsubsets(Life.expectancy~.,data=LifeExp[,!colnames(train) %in% drop_for_reg],method="backward",nvmax=24)
coef(mlr.bck.final,14)

summary(mlr.bck.final)

# Metrics RMSE; R-squared; MAE
postResample(pred = predictions, obs = ytest)

##different result now, will repeat steps from earlier model
### Continent
fit.bck.lm <- lm(Life.expectancy ~ Adult.Mortality+infant.deaths+Alcohol+under.five.deaths+Polio+
                                   Diphtheria+Income.composition.of.resources + Schooling + log.GDP
                 ,data = rtrain)

summary(fit.bck.lm)

### Visualize VIF
fit.bck.lm_VIF = vif(fit.bck.lm)
barplot(fit.bck.lm_VIF, main = 'VIF Values (Backward elimination)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

#two are correlated and giving a high VIF it's under.five and infant.deaths
fit.bck.lm2 <- lm(Life.expectancy ~ Adult.Mortality+Alcohol+under.five.deaths+Polio+
                                   Diphtheria+Income.composition.of.resources + Schooling + log.GDP,data = rtrain)


fit.bck.lm2_VIF = vif(fit.bck.lm2)
barplot(fit.bck.lm2_VIF, main = 'VIF Values (Backward elimination)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

##fit model with categorical variables and removed colinearity
# Continent
fit.bck.lm3 = lm(Life.expectancy ~ Status + Continent + Adult.Mortality+Alcohol+under.five.deaths+Polio+
                                   Diphtheria+Income.composition.of.resources + Schooling + log.GDP,data = rtrain)


#### Hypothesis testing ####
summary(fit.bck.lm3)

# Predicting
train_pred = predict(fit.bck.lm3, rtrain)
test_pred = predict(fit.bck.lm3, rtest)

# Scoring the final model on Training and Test set
residuals = resid(fit.bck.lm3)
train_score = postResample(pred = train_pred, obs = train$Life.expectancy)
test_score = postResample(pred = test_pred, obs = test$Life.expectancy)
sm = summary(fit.bck.lm3)
mse_trn = mean(sm$residuals^2)

### Checking Multiple Liner Regression model assumptions
confint(fit.bck.lm3)
hist(residuals, main = "Histogram of Residuals (Backward elimination)")
plot(residuals, main = "Residuals plot (Backward elimination)") 
abline(h=0, col="blue")
plot(fit.fwd.lm3, which = 2)
plot(fit.fwd.lm3, which = 4)

##### Visualize prediction vs actual
x_fwd = 1:dim(xtest)[1]
plot(x_fwd, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (Backward elimination)", ylab="Life expectancy")
lines(x_fwd, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()


#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (Backward elimination)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit.bck.lm3$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared




eval_test_df = rbind(eval_test_df, c('Backward Elim.', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('Backward Elim.', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse_trn,4),nsmall=4)))


#####################################################################################
#                                  Ridge regression                                 #
#####################################################################################

grid=10^seq(10,-2, length =100)
ridge.mod=glmnet(x,y,alpha=0, lambda =grid, family = 'gaussian') # alpha is 0 for Ridge
cv.out=cv.glmnet(x,y,alpha=0)
plot(cv.out)

bestlambda = cv.out$lambda.min  #Optimal penalty parameter.  You can make this call visually.
ridge.pred_trn=predict(ridge.mod ,s=bestlambda ,newx=x)
ridge.pred=predict(ridge.mod ,s=bestlambda ,newx=xtest)

testMSE_RIDGE<-mean((ytest-ridge.pred)^2)
testMSE_RIDGE
coef(ridge.mod,s=bestlambda)

# Metrics RMSE; R-squared; MAE
test_score = postResample(pred = ridge.pred, obs = ytest)
train_score = postResample(pred = ridge.pred_trn, obs = rtrain$Life.expectancy)


##### Visualize prediction vs actual
x_ridge = 1:dim(xtest)[1]
plot(x_fwd, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (Ridge Regression)", ylab="Life expectancy")
lines(x_fwd, ridge.pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(ridge.pred ~ ytest, main = "Original vs Predicted scatter plot (Ridge regression)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(coef(ridge.mod,s=bestlambda))-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = rmse_trn^2
n=dim(x)[1]
p = length(coef(ridge.mod,s=bestlambda))-1
adjrsqd_trn = 1 - (1 - rsqd_trn) * ((n - 1)/(n-p-1))

eval_test_df = rbind(eval_test_df, c('Ridge', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))
eval_train_df = rbind(eval_train_df, c('Ridge', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))


#####################################################################################
#                            Elastic Net Regression                                 #
#####################################################################################

library(glmnetUtils)
cva.out = cva.glmnet(x,y)
plot(cva.out)

alpha = cva.out$alpha
mse = sapply(cva.out$modlist, function(mod) {min(mod$cvm)})
lambdaMin <- sapply(cva.out$modlist, `[[`, "lambda.min")
min_mse <- which.min(mse)
cva.min = data.frame(alpha = alpha[min_mse], lambdaMin = lambdaMin[min_mse], mse = mse[min_mse])
cva.min

elastic.mod = glmnet(x,y, alpha = cva.min$alpha, lambda = cva.min$lambdaMin)
elastic.pred_trn=predict(elastic.mod ,s=cva.min$lambdaMin ,newx=x)
elastic.pred=predict(elastic.mod ,s=cva.min$lambdaMin ,newx=xtest)
elastic.pred_coef=predict(elastic.mod ,s=cva.min$lambdaMin ,newx=xtest, type = "coef")

testMSE_ELASTIC<-mean((ytest-elastic.pred)^2)
testMSE_ELASTIC

# Metrics RMSE; R-squared; MAE
train_score = postResample(pred = elastic.pred_trn, obs = rtrain$Life.expectancy)
test_score = postResample(pred = elastic.pred, obs = ytest)

##### Visualize prediction vs actual
x_eNET = 1:dim(xtest)[1]
plot(x_eNET, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (ElasticNet Regression)", ylab="Life expectancy")
lines(x_fwd, elastic.pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(elastic.pred ~ ytest, main = "Original vs Predicted scatter plot (ElasticNet regression)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(coef(elastic.mod))-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = rmse_trn^2
n=dim(x)[1]
p = length(coef(elastic.mod,s=bestlambda))-1
adjrsqd_trn = 1 - (1 - rsqd_trn) * ((n - 1)/(n-p-1))


eval_test_df = rbind(eval_test_df, c('ElasticNet', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('ElasticNet', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))

#####################################################################################
#                                      Manual MLR - Tamas                           #
#####################################################################################
# 5-fold cross validation
cv <- trainControl(
  method = "cv", 
  number = 5,
  savePredictions = TRUE
)

MLRT = train(
  Life.expectancy ~ Status + Continent + Income.composition.of.resources + Schooling + log.percentage.expenditure + Year + Adult.Mortality + infant.deaths,
  data = rtrain,
  method = "lm",
   preProcess = c("center", "scale"),
  trControl = cv)

### Visualize VIF
MLR_VIF = vif(MLRT$finalModel)
barplot(MLR_VIF, main = 'VIF Values (Custom MLR - Tamas)', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

### Hypothesis testing
summary(MLRT$finalModel)


# Predicting
train_pred = predict(MLRT, rtrain)
test_pred = predict(MLRT, rtest)

# Scoring the final model on Training and Test set
summary(MLRT$finalModel)
sm=summary(MLRT$finalModel)
mse_trn = mean(sm$residuals^2)
residuals = resid(MLRT$finalModel)
train_score = postResample(pred = train_pred, obs = rtrain$Life.expectancy)
test_score = postResample(pred = test_pred, obs = rtest$Life.expectancy)

### Checking Multiple Liner Regression model assumptions
fit = lm(Life.expectancy ~ Status + Continent + Income.composition.of.resources + Schooling + log.percentage.expenditure + Year + Adult.Mortality + infant.deaths, data = rtrain)
confint(fit)
hist(residuals, main = "Histogram of Residuals")
plot(residuals, main = "Residuals plot") 
abline(h=0, col="blue")
plot(fit, which = 2)
plot(fit, which = 4)


##### Visualize prediction vs actual
x_TMLR = 1:dim(xtest)[1]
plot(x_TMLR, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (Manual MLR)", ylab="Life expectancy")
lines(x_fwd, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (Custom MLR Tamas)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared


eval_test_df = rbind(eval_test_df, c('MLR - Tamas', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('MLR - Tamas', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))


```


```{r Objective 2 interaction}
#####################################################################################
#                                      Objective 2                                  #
#                   Model with complexity (adding interaction terms)                #
#####################################################################################
fit_interaction = lm(Life.expectancy ~ Continent + Schooling + log.percentage.expenditure + Year + Adult.Mortality + infant.deaths + Income.composition.of.resources:Status, train)

interact_pred_train = predict(fit_interaction, rtrain)
train_score = postResample(pred = interact_pred_train, obs = rtrain$Life.expectancy)

interact_pred = predict(fit_interaction, rtest)
test_score = postResample(pred = interact_pred, obs = rtest$Life.expectancy)

summary(fit_interaction)
confint(fit_interaction)
hist(residuals, main = "Histogram of Residuals (Interaction)")
plot(residuals, main = "Residuals plot (Interaction)") 
abline(h=0, col="blue")
plot(fit_interaction, which = 2)
plot(fit_interaction, which = 4)

##### Visualize prediction vs actual
x_TMLR = 1:dim(xtest)[1]
plot(x_TMLR, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (Interaction)", ylab="Life expectancy")
lines(x_fwd, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (Interaction)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit_interaction$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
sm = summary(fit_interaction)
mse_trn = mean(sm$residuals^2)
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared

eval_test_df = rbind(eval_test_df, c('MLR Interact - Tamas', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('MLR Interact - Tamas', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))

```

```{r}
#####################################################################################
#                                    Reuven's  Manual MLR Interaction                           #
#####################################################################################

# 5-fold cross validation
cv <- trainControl(
  method = "cv", 
  number = 5,
  savePredictions = TRUE
)
MLRT = train(
  Life.expectancy ~ Income.composition.of.resources + Schooling*log.percentage.expenditure  +  log.HIV.AIDS + log.GDP + BMI + Year + Adult.Mortality,
  data = rtrain,
  method = "lm",
  trControl = cv)

### Visualize VIF
MLR_VIF = vif(MLRT$finalModel)
barplot(MLR_VIF, main = 'VIF Values', horiz = TRUE, col="blue", xlim = c(0,12))
abline(v=10, col="red")

### Hypothesis testing
summary(MLRT$finalModel)
# Predicting
train_pred = predict(MLRT, rtrain)
test_pred = predict(MLRT, rtest)

# Scoring the final model on Training and Validation set
summary(MLRT$finalModel)
residuals = resid(MLRT$finalModel)
train_score = postResample(pred = train_pred, obs = rtrain$Life.expectancy)
test_score = postResample(pred = test_pred, obs = rtest$Life.expectancy)

### Checking Multiple Liner Regression model assumptions
fit = lm(Life.expectancy ~ Income.composition.of.resources + Schooling*log.percentage.expenditure  +  log.HIV.AIDS + log.GDP + BMI + Year + Adult.Mortality, rtrain)
confint(fit)
hist(residuals, main = "Histogram of Residuals")
plot(residuals, main = "Residuals plot") 
abline(h=0, col="blue")
plot(fit, which = 2)
plot(fit, which = 4)

anova(fit)

x_TMLR = 1:dim(xtest)[1]
plot(x_TMLR, ytest, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction (Manual MLR)", ylab="Life expectancy")
lines(x_fwd, test_pred, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (Custom MLR Reuven)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))


## Train scores
sm = summary(MLRT$finalModel)
mse_trn = mean(sm$residuals^2)
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared

eval_test_df = rbind(eval_test_df, c('MLR Interact - Reuven', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('MLR Interact - Reuven', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))

```

## Observations
* The interaction of Schooling:log.percentage.expenditure is not statistically significant (p-value=0.48) at the .05 alpha level, this indicates that the effect of schooling does not depend on the linear log of percentage expenditure as it relates to Life expectancy holding all other variables constant

* The interaction of Status:Continent is statistically significant (p-value < 0.0001) at the .05 alpha level, this indicates that the effect of whether a continent is developed or not does directly correspond to a higher Life expectancy holding all other variables constant.

* All other variables are statistically signficant for the model with an R-Squared on our prediction set of 0.8566.

```{r creating binary categorical variables}
#######################################################################################
#                               Manual MLR Miguel                                     #
#######################################################################################
#resplit here for now
index<-sample(1:dim(LifeExp)[1],round(dim(LifeExp)[1]*0.85),replace=F)
train = LifeExp[index,]
test = LifeExp[-index,]
#duplicate dataframe
LifeExp2 <- LifeExp
#create cat variables for HIV and Meas as binary No/Yes
LifeExp2 <- LifeExp2 %>% dplyr::mutate(HIV_cat = if_else(LifeExp2$log.HIV.AIDS>log(.1),1,0),
                                       Meas_cat= if_else(LifeExp2$Measles>0,1,0),
                                       log.Adult.Mortality = log(Adult.Mortality),
                                       log.infant.deaths = log(infant.deaths))
train_custom <- LifeExp2[index,]
test_custom <- LifeExp2[-index,]
```
```{r run custom model}
#retrain/fit/test/predict and measure accuracy
fit.custom <- lm(Life.expectancy ~log.Adult.Mortality + infant.deaths + log.GDP + Measles + HIV_cat + Country + Country:infant.deaths +Country:log.Adult.Mortality + log.Adult.Mortality:infant.deaths:Country,data = train_custom)
#model has interactions between HIV and Measles variables and their respective
#binary categories to have a sort of conditional
#interaction between Country:infant.deaths
#check model performance on the test set and test set prediction
train_custom_pred <- predict(fit.custom,train_custom)
test_custom_pred <- predict(fit.custom,test_custom) #rank deficient warning comes from the self-interactions (ex. HIV_cat:HIV)
test_score = caret::postResample(pred = test_custom_pred,obs = test_custom$Life.expectancy)
train_score = caret::postResample(pred = train_custom_pred,obs = train_custom$Life.expectancy)
forecast::accuracy(test_custom_pred,test_custom$Life.expectancy)


#### Scatter plot
plot(test_pred ~ ytest, main = "Original vs Predicted scatter plot (Custom MLR Miguel)", xlab = 'Original observations', ylab='Predicted values')

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(fit.custom$coefficients)-1
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
sm=summary(fit.custom)
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trn = rmse_trn^2
mse_trndf = mse_trn
adjrsqd_trn = sm$adj.r.squared

eval_test_df = rbind(eval_test_df, c('MLR Interact - Miguel', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))

eval_train_df = rbind(eval_train_df, c('MLR Interact - Miguel', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))


```





```{r Objective 2 KNN}
#####################################################################################
#                                      Objective 2                                  #
#                                     KNN - regression                              #
#####################################################################################
# Check for zero variance
caret::nearZeroVar(LifeExp %>% dplyr::select(where(is.numeric)), saveMetrics = TRUE) %>% 
  tibble::rownames_to_column() %>% 
  filter(nzv)
cat("No variable with zero variance in the selected list of variables.") 


# Search for optimal k
k_grid = expand.grid(k = seq(3, 25, by = 2))

# Model Training
KNNRegressor = train(
  Life.expectancy~.,
  data = ktrain,
  method = "knn",
  preProcess = c("center", "scale"), 
  tuneGrid = k_grid,
  metric     = "RMSE",
  trControl = cv
  )

prediction_test = predict(KNNRegressor, ktrain)
train_score = postResample(pred = prediction_test, obs = ktrain$Life.expectancy)

prediction_test = predict(KNNRegressor, ktest)
test_score = postResample(pred = prediction_test, obs = ktest$Life.expectancy)

plot(KNNRegressor)
varImp(KNNRegressor)

#KNNRegressor$results$Rsquared
#KNNRegressor.sorted <- KNNRegressor$results[order(KNNRegressor$results$Rsquared),]
#KNNRegressor.sorted[1,'Rsquared']

x_knn = 1:length(ktest$Life.expectancy)
plot(x_knn, ktest$Life.expectancy, col = "red", type = "l", lwd=2,
     main = "Life Expectancy prediction")
lines(x_knn, prediction_test, col = "blue", lwd=2)
legend("topright",  legend = c("original observation", "predicted life expectancy"), 
       fill = c("red", "blue"), col = 2:3,  adj = c(0, 0.6))
grid()

#### Model test scores
rmse = test_score[1]
rsqd = test_score[2]
mse = rmse^2
n=dim(xtest)[1]
p = length(KNNRegressor$coefnames)
adjrsqd = 1 - (1 - rsqd) * ((n - 1)/(n-p-1))

## Train scores
rmse_trn = train_score[1]
rsqd_trn = train_score[2]
mse_trn = rmse^2
mse_trndf = mse_trn
n=dim(xtest)[1]
p = length(KNNRegressor$coefnames)
adjrsqd_trn = 1 - (1 - rsqd_trn) * ((n - 1)/(n-p-1))

eval_test_df = rbind(eval_test_df, c('KNN', format(round(mse,4),nsmall=4), format(round(rsqd,4),nsmall=4), format(round(adjrsqd,4),nsmall=4), format(round(rmse,4),nsmall=4)))
eval_train_df = rbind(eval_train_df, c('KNN', format(round(mse_trndf,4),nsmall=4), format(round(rsqd_trn,4),nsmall=4), format(round(adjrsqd_trn,4),nsmall=4), format(round(rmse,4),nsmall=4)))

```

### Visualize 'k' and the most important features
```{r, fig.align='center',out.extra='angle=90'}
# Visualize 'k' and the most important features
ggplot(KNNRegressor) + ggtitle("Optimal k value for the highest accuracy") +
  theme(plot.title = element_text(hjust = 0.5))
KNNvarImp = varImp(KNNRegressor)
plot(KNNvarImp, top = 5, main='Top 5 Variable predicting life expectancy (KNN)')
```

# Training set scores
```{r}
knitr::kable(eval_train_df, "html")
```


# Test set scores
```{r}
knitr::kable(eval_test_df, "html")
```
